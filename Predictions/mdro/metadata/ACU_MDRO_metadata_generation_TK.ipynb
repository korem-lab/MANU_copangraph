{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# constants\n",
    "MIN_T = 3\n",
    "MAX_T = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous label sets\n",
    "mdro_pos_large = pd.read_csv('./mdro_large_metadata.csv')\n",
    "mdro_pos_large.sort_values(['StudyID', 'SampleDate'], inplace=True)\n",
    "mdro_pos_large.index = mdro_pos_large['Stool ID']\n",
    "mdro_pos_small = pd.read_csv('./mdro_pos.csv')\n",
    "mdro_pos_small.sort_values(['StudyID', 'SampleDate'], inplace=True)\n",
    "mdro_pos_small.index = mdro_pos_small['Stool ID']\n",
    "\n",
    "\n",
    "# previous StudyID\n",
    "mdro_pos_large_sid = mdro_pos_large.StudyID.unique()\n",
    "mdro_pos_small_sid = mdro_pos_small.StudyID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "md = pd.read_excel('PLT_all_stool_isolates_seq_old.xlsx')\n",
    "md.sort_values(['StudyID', 'SampleDate'], inplace=True)\n",
    "\n",
    "# select only the patients relevant for each dataset\n",
    "md_large = md.loc[md.StudyID.isin(mdro_pos_large_sid),:]\n",
    "md_large.reset_index(drop=True, inplace=True)\n",
    "md_small = md.loc[md.StudyID.isin(mdro_pos_small_sid),:]\n",
    "md_small.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# assert patient list is the same, in the same order\n",
    "assert(all(md_large.StudyID.unique() == mdro_pos_large_sid))\n",
    "assert(all(md_small.StudyID.unique() == mdro_pos_small_sid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_MDRO(s):\n",
    "    rgx=r'3\\d{4}'\n",
    "    esbl, kpc, vre = s[['ESBLisolate', 'KPCisolate', 'VRE +/-']]\n",
    "    esbl = str(esbl)\n",
    "    kpc = str(kpc)\n",
    "    vre = str(vre)\n",
    "    if ('+' in esbl or '+' in kpc or '+' in vre):\n",
    "        return True\n",
    "    elif re.search(rgx, esbl) or re.search(rgx, kpc) or re.search(rgx, vre):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "persistence\n",
       "True     39\n",
       "False    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MDRO_POS_SMALL ANALYSIS\n",
    "\n",
    "min_t = pd.Timedelta(days=MIN_T)\n",
    "max_t = pd.Timedelta(days=MAX_T)\n",
    "corrected_mdro_pos_small = pd.DataFrame(\n",
    "    columns = ['Stool ID', 'SampleDate', 'StudyID', 'TxDate', 'ESBLisolate', 'KPCisolate', 'VRE +/-', 'MDRO'] + [\n",
    "        'Future_Stool_ID', 'Future_SampleDate', 'Future_ESBLisolate', 'Future_KPCisolate', 'Future_VRE_+/-', 'MIN_T', 'MAX_T', 'persistence'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get a pointer to the location of each sample in mdro_pos to its location in metadata. \n",
    "small_stool_mdidx = md_small.index[md_small['Stool ID'].isin(mdro_pos_small['Stool ID'])]\n",
    "\n",
    "# make sure the samples pointed to are the same\n",
    "assert(all(md_small.loc[small_stool_mdidx, 'Stool ID'].values == mdro_pos_small['Stool ID'].values))\n",
    "\n",
    "# md_small and mdro_pos_small are both ordered by ['Study ID', 'Sample Date'], and there is one sample per Study ID (patient) in mdro_pos_small\n",
    "# Therefore the ith sample in mdro_stool_mdidx is from the same StudyID as the ith iterate of md_small.groupby('StudyID) \n",
    "for i, (sid, df) in enumerate(md_small.groupby('StudyID')):\n",
    "    \n",
    "    # For the the current patient (Study ID), \n",
    "    # get the sample selected in mdro_pos_small plus all samples collected after it\n",
    "    df_sample_future = df.loc[small_stool_mdidx[i]:, ]\n",
    "    \n",
    "    # filter on the time window\n",
    "    # Get the delta in days between the sample in mdro_pos and future sample\n",
    "    delta_t = df_sample_future.loc[:, 'SampleDate'] - df.loc[small_stool_mdidx[i], 'SampleDate']\n",
    "    \n",
    "    # only select samples in the [MIN_T, MAX_T]  window\n",
    "    t_filter = ((min_t <= delta_t) & (delta_t <= max_t))\n",
    "    df_sample_future = df_sample_future.loc[t_filter, :]\n",
    "    \n",
    "    # assign persistence label based on closest collected future sample\n",
    "    persistence = any_MDRO(df_sample_future.iloc[0, :])\n",
    "    \n",
    "    # store mdro_pos_small metadata\n",
    "    corrected_mdro_pos_small.loc[len(corrected_mdro_pos_small), :] = \\\n",
    "        list(df.loc[small_stool_mdidx[i], ['Stool ID', 'SampleDate', 'StudyID', 'TxDate', 'ESBLisolate', 'KPCisolate', 'VRE +/-']]) + \\\n",
    "        [any_MDRO(df.loc[small_stool_mdidx[i], :])] + \\\n",
    "        list(df_sample_future.iloc[0, :][['Stool ID', 'SampleDate', 'ESBLisolate', 'KPCisolate', 'VRE +/-']]) + \\\n",
    "        [MIN_T, MAX_T, persistence]\n",
    "corrected_mdro_pos_small.to_csv('corrected_mdro_pos_small.csv')\n",
    "corrected_mdro_pos_small.persistence.value_counts() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "persistence\n",
       "True     58\n",
       "False    40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MDRO_POS_LARGE_ANALYSIS\n",
    "\n",
    "min_t = pd.Timedelta(days=MIN_T)\n",
    "max_t = pd.Timedelta(days=MAX_T)\n",
    "corrected_mdro_pos_large = pd.DataFrame(\n",
    "    columns = ['Stool ID', 'SampleDate', 'StudyID', 'TxDate', 'ESBLisolate', 'KPCisolate', 'VRE +/-', 'MDRO'] + [\n",
    "        'Future_Stool_ID', 'Future_SampleDate', 'Future_ESBLisolate', 'Future_KPCisolate', 'Future_VRE_+/-', 'MIN_T', 'MAX_T', 'persistence'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get a pointer to the location of each sample in mdro_pos to its location in metadata. \n",
    "large_stool_mdidx = md_large.index[md_large['Stool ID'].isin(mdro_pos_large['Stool ID'])]\n",
    "\n",
    "# make sure the samples pointed to are the same\n",
    "assert(all(md_large.loc[large_stool_mdidx, 'Stool ID'].values == mdro_pos_large['Stool ID'].values))\n",
    "\n",
    "# md_large and mdro_pos_large are both ordered by ['Study ID', 'Sample Date'], and there is one sample per Study ID (patient) in mdro_pos_large\n",
    "# Therefore the ith sample in mdro_stool_mdidx is from the same StudyID as the ith iterate of md_large.groupby('StudyID) \n",
    "for i, (sid, df) in enumerate(md_large.groupby('StudyID')):\n",
    "    \n",
    "    # For the the current patient (Study ID), \n",
    "    # get the sample selected in mdro_pos_large plus all samples collected after it\n",
    "    df_sample_future = df.loc[large_stool_mdidx[i]:, ]\n",
    "    \n",
    "    # filter on the time window\n",
    "    # Get the delta in days between the sample in mdro_pos and future sample\n",
    "    delta_t = df_sample_future.loc[:, 'SampleDate'] - df.loc[large_stool_mdidx[i], 'SampleDate']\n",
    "    \n",
    "    # only select samples in the [MIN_T, MAX_T]  window\n",
    "    t_filter = ((min_t <= delta_t) & (delta_t <= max_t))\n",
    "    df_sample_future = df_sample_future.loc[t_filter, :]\n",
    "    \n",
    "    # assign persistence label based on closest collected future sample\n",
    "    persistence = any_MDRO(df_sample_future.iloc[0, :])\n",
    "    \n",
    "    # store mdro_pos_large metadata\n",
    "    corrected_mdro_pos_large.loc[len(corrected_mdro_pos_large), :] = \\\n",
    "        list(df.loc[large_stool_mdidx[i], ['Stool ID', 'SampleDate', 'StudyID', 'TxDate', 'ESBLisolate', 'KPCisolate', 'VRE +/-']]) + \\\n",
    "        [any_MDRO(df.loc[large_stool_mdidx[i], :])] + \\\n",
    "        list(df_sample_future.iloc[0, :][['Stool ID', 'SampleDate', 'ESBLisolate', 'KPCisolate', 'VRE +/-']]) + \\\n",
    "        [MIN_T, MAX_T, persistence]\n",
    "corrected_mdro_pos_large.to_csv('corrected_mdro_pos_large.csv')\n",
    "corrected_mdro_pos_large.persistence.value_counts() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2056, 7)\n",
      "(2036, 7)\n"
     ]
    }
   ],
   "source": [
    "islts = pd.read_excel('/Users/talkorem/Library/CloudStorage/Dropbox/Columbia/Projects/ACU_PLT/PLT_all_stool_isolates.xlsx')\n",
    "\n",
    "islts.rename(columns = {'Stool ID':'StoolID', 'VRE +/-':'VRE'}, inplace = True)\n",
    "\n",
    "islts = islts[islts.StudyID.notnull()] #lose 2 samples\n",
    "islts = islts[~islts.ESBLisolate.apply(lambda v: type(v) is str and \"SAME AS\" in v)]#remove 4 duplciates\n",
    "islts.head()\n",
    "\n",
    "islts['ESBL'] = islts.ESBLisolate.replace([0, 'N', 'No', '-', 'n', 'N (NO MAC GROWTH)', 'N (ODD)'], 'No').\\\n",
    "    replace(['?', '35379- FALSE + DUE TO BAD PLATES', '35387 (FALSE + DUE TO BAD PLATES)',\n",
    "            '35393 (FALSE + DUE TO BAD PLATES)'], np.nan).\\\n",
    "     apply(lambda v: np.nan if type(v) is str and 'BOTH FALSE + DUE TO BAD PLATES' in v else v)\n",
    "\n",
    "islts['KPC'] = islts.KPCisolate.replace(['N', 'n', '-', 0, 'N (AFTER SUB CX)', 'N (NO MAC GROWTH)'], 'No').\\\n",
    "                 replace(['?', 'N (SMALL BLUE?)', '?N '], np.nan)\n",
    "\n",
    "islts['VRE'] = islts.VRE.replace(['N', '-', 'n', '0'], 'No').replace(['+ (NEG on reculture 3/31)', 'NEG on reculture 4/12'], np.nan).\\\n",
    "    replace(['+', '+ (not pink)', '+ (mauve + blue)', '+ (pink + white)', '+ (mauve)', '+ (white)'], 'Yes')\n",
    "\n",
    "\n",
    "islts = islts.drop(['ESBLisolate', 'KPCisolate'], axis = 1)\n",
    "\n",
    "#PTNT 186 IS WEIRD W 31331 31332\n",
    "dupstlid = [31012, 30522, 30100, 30176, 30947, 30327, 30483, 30496, 30919, 31098, \n",
    "            31332, 30973, 31277, 31820, 31501, 31899, 31828, 31884, 31808, 32033]\n",
    "\n",
    "print(islts.shape)\n",
    "islts = islts[~islts.StoolID.isin(dupstlid)]\n",
    "print(islts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "islts['Clear'] = (islts[['VRE', 'ESBL', 'KPC']] == 'No').all(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_2/6s8sdjc954jgbjphzbjvzdym0000gn/T/ipykernel_39261/3022813693.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  islts['Positive'] = islts[['VRE', 'ESBL', 'KPC']].applymap(lambda v: v != 'No' and pd.notnull(v)).any(axis=1)\n"
     ]
    }
   ],
   "source": [
    "islts['Positive'] = islts[['VRE', 'ESBL', 'KPC']].applymap(lambda v: v != 'No' and pd.notnull(v)).any(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "git = iter(islts.groupby('StudyID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome(g):\n",
    "    g = g.sort_values('SampleDate')\n",
    "    g = g[(g[['Clear', 'Positive']] == True).any(axis=1)]\n",
    "    gj = g.join(g.shift(-1), rsuffix='_nxt')\n",
    "    gj = gj[((gj.SampleDate_nxt - gj.SampleDate) >= min_t) & ((gj.SampleDate_nxt - gj.SampleDate) < max_t)]\n",
    "    gj['Outcome'] = gj.apply(lambda r: 'Clearance' if r['Clear_nxt'] == True else 'Persistence' if r['Positive_nxt'] == True else np.nan, axis = 1)\n",
    "    return gj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = islts.groupby('StudyID').apply(get_outcome, include_groups=False).reset_index().drop('level_1', axis = 1)\n",
    "outcome = outcome[outcome.Positive]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "persistence  Outcome    \n",
       "False        Clearance       8\n",
       "             Persistence     1\n",
       "             NaN             1\n",
       "True         Persistence    36\n",
       "             NaN             3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_mdro_pos_small[['Stool ID', 'persistence']].merge(outcome, left_on='Stool ID', right_on = 'StoolID', how='left')[['persistence', 'Outcome']].value_counts(dropna=False).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "persistence  Outcome    \n",
       "False        Clearance      34\n",
       "             NaN             6\n",
       "True         Persistence    54\n",
       "             NaN             4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_mdro_pos_large[['Stool ID', 'persistence']].merge(outcome, left_on='Stool ID', right_on = 'StoolID', how='left')[['persistence', 'Outcome']].value_counts(dropna=False).sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
