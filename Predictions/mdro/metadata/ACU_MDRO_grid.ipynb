{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# constants\n",
    "MIN_T = 3\n",
    "MAX_T = 28\n",
    "min_t = pd.Timedelta(days=MIN_T)\n",
    "max_t = pd.Timedelta(days=MAX_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "(2056, 7)\n",
      "(25, 7)\n",
      "(2081, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145721/952736823.py:52: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dups = islts.groupby(['StudyID', 'SampleDate']).apply(lambda x: x[x.seqALL] if (len(x) > 1 and x.seqALL.any()) else None)\n",
      "/tmp/ipykernel_145721/952736823.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sngltns = islts.groupby(['StudyID', 'SampleDate']).apply(lambda x: x if len(x) == 1 else None)\n"
     ]
    }
   ],
   "source": [
    "# RAW DFS\n",
    "islts = pd.read_excel('PLT_all_stool_isolates.xlsx')\n",
    "islts.rename(columns = {'Stool ID':'StoolID', 'VRE +/-':'VRE'}, inplace = True)\n",
    "islts = islts[islts.StudyID.notnull()] #lose 2 samples\n",
    "islts = islts[~islts.ESBLisolate.apply(lambda v: type(v) is str and \"SAME AS\" in v)]#remove 4 duplciates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clean mdro type vars\n",
    "islts['ESBL'] = islts.ESBLisolate.replace([0, 'N', 'No', '-', 'n', 'N (NO MAC GROWTH)', 'N (ODD)'], 'No').\\\n",
    "    replace(['?', '35379- FALSE + DUE TO BAD PLATES', '35387 (FALSE + DUE TO BAD PLATES)',\n",
    "            '35393 (FALSE + DUE TO BAD PLATES)'], np.nan).\\\n",
    "     apply(lambda v: np.nan if type(v) is str and 'BOTH FALSE + DUE TO BAD PLATES' in v else v)\n",
    "\n",
    "islts['KPC'] = islts.KPCisolate.replace(['N', 'n', '-', 0, 'N (AFTER SUB CX)', 'N (NO MAC GROWTH)'], 'No').\\\n",
    "                 replace(['?', 'N (SMALL BLUE?)', '?N '], np.nan)\n",
    "\n",
    "islts['VRE'] = islts.VRE.replace(['N', '-', 'n', '0'], 'No').replace(['+ (NEG on reculture 3/31)', 'NEG on reculture 4/12'], np.nan).\\\n",
    "    replace(['+', '+ (not pink)', '+ (mauve + blue)', '+ (pink + white)', '+ (mauve)', '+ (white)'], 'Yes')\n",
    "    \n",
    "islts = islts.drop(['ESBLisolate', 'KPCisolate'], axis = 1)\n",
    "\n",
    "missing = [302615, 303205, 303955, 304362, 311175, 31117, 312645, 319365, 320275, 320315, 320515, 320525, 32073, 32077, 32088, 32089, 32090, 32096, 32098, 32101, 32106, 32107, 32108, 32119, 32138, 32141, 321481, 321482, 32152, 32173, 32177, 32184, 32196, 32197, 32198, 32221, 32235, 32238]\n",
    "print(len(missing))\n",
    "stlbk = pd.read_excel('StoolBookDeidentified20241023.xlsx')\n",
    "stlbk.rename({'Stool_ID': 'StoolID'}, inplace=True, axis=1)\n",
    "stlbk = stlbk.loc[stlbk.StoolID.isin(missing), :].drop(['ESBL_Growth', 'KPC_Growth', 'VRE_Growth'], axis=1)\n",
    "mkstr = lambda x: f'{int(x)},' if pd.notna(x) else ''\n",
    "stlbk['VRE'] = stlbk.apply(lambda r: 'No' if r[['VRE1', 'VRE2', 'VRE3']].isnull().all() else mkstr(r.VRE1)+mkstr(r.VRE2)+mkstr(r.VRE3), axis=1).apply(lambda x: x[:-1] if x.endswith(',') else x)\n",
    "stlbk['ESBL'] = stlbk.apply(lambda r: 'No' if r[['ESBL1', 'ESBL2', 'ESBL3']].isnull().all() else mkstr(r.ESBL1)+mkstr(r.ESBL2)+mkstr(r.ESBL3), axis=1).apply(lambda x: x[:-1] if x.endswith(',') else x)\n",
    "stlbk['KPC'] = stlbk.apply(lambda r: 'No' if r[['KPC1', 'KPC2', 'KPC3']].isnull().all() else mkstr(r.KPC1)+mkstr(r.KPC2)+mkstr(r.KPC3), axis=1).apply(lambda x: x[:-1] if x.endswith(',') else x)\n",
    "stlbk.drop(['VRE1', 'VRE2', 'VRE3', 'ESBL1', 'ESBL2', 'ESBL3', 'KPC1', 'KPC2', 'KPC3'], axis=1, inplace=True)\n",
    "stlbk['TxDate'] = stlbk.StudyID.apply(lambda x: islts.loc[islts.StudyID == int(x), 'TxDate'].iloc[0] if not islts.loc[islts.StudyID == int(x), 'TxDate'].empty else pd.NaT)\n",
    "stlbk.rename({'Sample_Date':'SampleDate'}, axis=1, inplace=True)\n",
    "print(islts.shape)\n",
    "print(stlbk.shape)\n",
    "islts = pd.concat([islts, stlbk])\n",
    "print(islts.shape)\n",
    "\n",
    "# ADD SEQUENCE INFO\n",
    "r = pd.read_pickle('RawMetadata.df')\n",
    "islts['StoolIDstr'] = islts.StoolID.astype(str)\n",
    "islts['seq2020'] = islts.StoolIDstr.isin(r[r.index.get_level_values(1) == '2020'].index.get_level_values(0))\n",
    "islts['seq2022'] = islts.StoolIDstr.isin(r[r.index.get_level_values(1) == '2022'].index.get_level_values(0))\n",
    "islts['seq2023'] = islts.StoolIDstr.isin(r[r.index.get_level_values(1) == '2023'].index.get_level_values(0))\n",
    "islts['seqALL'] = islts['seq2020'] | islts['seq2022'] | islts['seq2023']\n",
    "islts = islts.merge(r.groupby(level=0).sum()[['PostHGFRC2']], left_on='StoolIDstr', right_index=True, how = 'left')\n",
    "islts = islts.drop('StoolIDstr', axis = 1)\n",
    "islts\n",
    "\n",
    "dups = islts.groupby(['StudyID', 'SampleDate']).apply(lambda x: x[x.seqALL] if (len(x) > 1 and x.seqALL.any()) else None)\n",
    "sngltns = islts.groupby(['StudyID', 'SampleDate']).apply(lambda x: x if len(x) == 1 else None)\n",
    "islts = pd.concat([sngltns, dups])\n",
    "# CHECK THAT WHAT WE'RE DROPPING IS THE NON_SEQ DUPLICATES\n",
    "##PTNT 186 IS WEIRD W 31331 31332\n",
    "#dupstlid = [31012, 30522, 30100, 30176, 30947, 30327, 30483, 30496, 30919, 31098, \n",
    "#            31332, 30973, 31277, 31820, 31501, 31899, 31828, 31884, 31808, 32033]\n",
    "#islts = islts[~islts.StoolID.isin(dupstlid)]\n",
    "#islts.shape\n",
    "#PATH_TO_PE_EXT = '/manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs'\n",
    "#islts['PATH'] = islts.StoolID.apply(lambda x: f'{PATH_TO_PE_EXT}/{x}.pe_ext.fasta')\n",
    "#\n",
    "#\n",
    "#\n",
    "## ABX\n",
    "#abx  = pd.read_excel('PLT_Abx_Courses_Tal2.xlsx').iloc[:, :4]\n",
    "#tx = islts[['TxDate', 'StudyID']].dropna().drop_duplicates()\n",
    "#tx.index = tx.StudyID\n",
    "#tx = tx.TxDate\n",
    "#abx['course_start_date'] = abx.apply(lambda r: tx[r.StudyID] + pd.Timedelta(days=r.course_start_daysposttx), axis=1)\n",
    "#abx['course_end_date'] = abx.apply(lambda r: tx[r.StudyID] + pd.Timedelta(days=r.course_end_daysposttx), axis=1)\n",
    "#abx['course_duration'] = (abx.course_end_daysposttx - abx.course_start_daysposttx) + 1\n",
    "#abx\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABX FUNCTIONS\n",
    "def course_days_to_date(abx_df, date):\n",
    "    if abx_df.empty:\n",
    "        return np.nan\n",
    "    days = abx_df.loc[abx_df.course_end_date < date, 'course_duration'].sum()\n",
    "    days = pd.Timedelta(days=days)\n",
    "    if any((abx_df.course_start_date <= date) & (date <= abx_df.course_end_date)):\n",
    "        days += (date - abx_df.loc[(abx_df.course_start_date <= date) & (date <= abx_df.course_end_date), :].course_start_date).sum() + pd.Timedelta(days=1)\n",
    "    return days.days\n",
    "\n",
    "def days_since_last_exposure(abx_df, date):\n",
    "    if abx_df.empty:\n",
    "        return np.nan\n",
    "    if any((abx_df.course_start_date <= date) & (date <= abx_df.course_end_date)):\n",
    "        # sample taken during exposure\n",
    "        return 0\n",
    "    if any(abx_df.course_end_date < date):\n",
    "        return (date - abx_df.loc[abx_df.course_end_date < date,'course_end_date']).min().days\n",
    "    \n",
    "def days_exposure_btwn(abx_df, sample, future):\n",
    "    if abx_df.empty:\n",
    "        return np.nan\n",
    "    ovlp_s = abx_df.course_start_date.apply(lambda x: max(x, sample))\n",
    "    ovlp_e = abx_df.course_end_date.apply(lambda x: min(x, future))\n",
    "    ovlp = (ovlp_e - ovlp_s).apply(lambda x: 0 if x.days < 0 else x.days + 1)\n",
    "    return ovlp.sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METADATA AND OUTCOME FUNCTIONS\n",
    "\n",
    "def get_vars(mdro_span, g):\n",
    "    StudyID = g.name\n",
    "    g = g.sort_values('SampleDate')\n",
    "    g['Clear'] = (g[mdro_span] == 'No').all(axis=1)\n",
    "    g['Positive'] = g[mdro_span].apply(lambda v: (v != 'No') & pd.notnull(v), axis=1).any(axis=1)\n",
    "    g = g[(g[['Clear', 'Positive']] == True).any(axis=1)]\n",
    "    gj = g.join(g.shift(-1), rsuffix='_nxt')\n",
    "    gj['tx_to_sample_days'] = (gj.SampleDate - gj.TxDate).apply(lambda x: x.days)\n",
    "    gj['sample_to_future_days'] = (gj.SampleDate_nxt - gj.SampleDate).apply(lambda x: x.days)\n",
    "    gj['course_days_total'] = abx.loc[abx.StudyID == StudyID, 'course_duration'].sum()\n",
    "    gj['course_days_to_sample'] = gj.apply(lambda r: course_days_to_date(abx.loc[abx.StudyID == StudyID,:], r.SampleDate), axis=1)\n",
    "    gj['course_days_to_future'] = gj.apply(lambda r: course_days_to_date(abx.loc[abx.StudyID == StudyID, :], r.SampleDate_nxt), axis=1)\n",
    "    gj['course_days_since_last_exposure'] = gj.apply(lambda r: days_since_last_exposure(abx.loc[abx.StudyID == StudyID, :], r.SampleDate), axis=1)\n",
    "    gj['course_days_between'] = gj.apply(lambda r: days_exposure_btwn(abx.loc[abx.StudyID == StudyID, :], r.SampleDate, r.SampleDate_nxt), axis=1)\n",
    "    #print(gj.to_string())\n",
    "    return gj\n",
    "\n",
    "def get_outcome(w, timetx, maxabx, clrlgc, seqstat, min_reads, g):\n",
    "    g = g.sort_values('SampleDate')\n",
    "    w_filt  = (w[0] <= g.sample_to_future_days) & (g.sample_to_future_days <= w[1])\n",
    "    \n",
    "    \n",
    "    tx_filt =  (timetx[0] <= g.tx_to_sample_days) & (g.tx_to_sample_days <= timetx[1])\n",
    "    # if you don't care allow nan\n",
    "    if timetx == (-np.inf, np.inf):\n",
    "        tx_filt |= g.tx_to_sample_days.isna()\n",
    "    \n",
    "    abx_filt = g.course_days_between <= maxabx\n",
    "    # if you don't care, allow nan\n",
    "    if maxabx == np.inf:\n",
    "        abx_filt |= g.course_days_between.isna()\n",
    "    \n",
    "    mrd_filt = g.PostHGFRC2 >= min_reads\n",
    "    pos_filt = g.Positive\n",
    "    \n",
    "    if seqstat == 'seqALL':\n",
    "        seq_filt = g.seqALL\n",
    "    elif seqstat == 'seq2023':\n",
    "        seq_filt = g.seq2023\n",
    "    elif seqstat == 'seq2022':\n",
    "        seq_filt = g.seq2022\n",
    "    elif seqstat == 'seq2020':\n",
    "        seq_filt = g.seq2020\n",
    "    elif seqstat is None:\n",
    "        seq_filt = np.full((g.shape[0],), True)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    filt = w_filt & abx_filt & tx_filt & pos_filt & seq_filt & mrd_filt\n",
    "        \n",
    "    #print('remaining:',  (w_filt & tx_filt & abx_filt & seq_filt).sum())\n",
    "    if clrlgc == 'allclr':\n",
    "        outcome = g.apply(lambda r: 'Clearance' if r['Clear_nxt'] == True else 'Persistence' if r['Positive_nxt'] == True else np.nan, axis = 1)\n",
    "        outcome.loc[~filt] = np.nan\n",
    "    elif clrlgc == 'typedclr':\n",
    "        outcome = g.apply(lambda r: 'Persistence' if any(np.all(np.vstack([r[['VRE_nxt', 'KPC_nxt', 'ESBL_nxt']].apply(lambda x: x != 'No' and pd.notnull(x)), r[['VRE', 'KPC', 'ESBL']].apply(lambda x: x != 'No' and pd.notnull(x))]), axis=0)) else 'Clearence', axis = 1)\n",
    "        outcome.loc[~filt] = np.nan\n",
    "    else:\n",
    "        raise Exception\n",
    "    return outcome\n",
    "    \n",
    "def allclr(g):\n",
    "    g = g.sort_values('SampleDate')\n",
    "    g = g[(g[['Clear', 'Positive']] == True).any(axis=1)]\n",
    "    gj = g.join(g.shift(-1), rsuffix='_nxt')\n",
    "    gj = gj[((gj.SampleDate_nxt - gj.SampleDate) >= min_t) & ((gj.SampleDate_nxt - gj.SampleDate) <= max_t)]\n",
    "    gj['Outcome'] = gj.apply(lambda r: 'Clearance' if r['Clear_nxt'] == True else 'Persistence' if r['Positive_nxt'] == True else np.nan, axis = 1)\n",
    "    #print(gj.to_string())\n",
    "    return gj\n",
    "\n",
    "def spfcclr(g):\n",
    "    g = g.sort_values('SampleDate')\n",
    "    g = g[(g[['Clear', 'Positive']] == True).any(axis=1)]\n",
    "    gj = g.join(g.shift(-1), rsuffix='_nxt')\n",
    "    gj = gj[((gj.SampleDate_nxt - gj.SampleDate) >= min_t) & ((gj.SampleDate_nxt - gj.SampleDate) <= max_t)]\n",
    "    gj['Outcome'] = gj.apply(lambda r: 'Persistence' if any(np.all(np.vstack([r[['VRE_nxt', 'KPC_nxt', 'ESBL_nxt']].apply(lambda x: x != 'No' and pd.notnull(x)), r[['VRE', 'KPC', 'ESBL']].apply(lambda x: x != 'No' and pd.notnull(x))]), axis=0)) else 'Clearence', axis = 1)\n",
    "    return gj\n",
    "\n",
    "#def get_outcome(g):\n",
    "#    g = g.sort_values('SampleDate')\n",
    "#    g = g[(g[['Clear', 'Positive']] == True).any(axis=1)]\n",
    "#    gj = g.join(g.shift(-1), rsuffix='_nxt')\n",
    "#    gj = gj[((gj.SampleDate_nxt - gj.SampleDate) >= min_t) & ((gj.SampleDate_nxt - gj.SampleDate) < max_t)]\n",
    "#    gj['Outcome'] = gj.apply(lambda r: 'Clearance' if r['Clear_nxt'] == True else 'Persistence' if r['Positive_nxt'] == True else np.nan, axis = 1)\n",
    "#    return gj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145721/2111453174.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outcome = islts.groupby('StudyID').apply(gv, include_groups=False).reset_index().drop('level_1', axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  120\n",
      "Patients:  93\n",
      "Outcome_allmdro_allclr_txany_abxany_w3-28_seqALL\n",
      "Persistence    83\n",
      "Clearance      37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# GRID COMPUTE METADATA\n",
    "MIN_READS=5*10**6\n",
    "MIN_SAMPLES=30\n",
    "MIN_LEAST_REPR_LABEL=10\n",
    "# ALL MDRO\n",
    "windows = [(3, 28)]#, (3, 21), (7, 21), (7, 28), (3, 14)]\n",
    "time_from_tx = [(-np.inf, np.inf)]\n",
    "abxbtwn = [np.inf]\n",
    "clearance_logic = ['allclr']\n",
    "seq_stat = ['seqALL']#, 'seq2022']#, None]\n",
    "mdro_span = ['VRE', 'ESBL', 'KPC']\n",
    "gv = partial(get_vars, mdro_span)\n",
    "outcome = islts.groupby('StudyID').apply(gv, include_groups=False).reset_index().drop('level_1', axis=1)\n",
    "# CHECK: Will get 614 in Tal version when selecting Positive samples but commenting out window filter\n",
    "for w, timetx, maxabx, clrlgc, sqst in product(windows, time_from_tx, abxbtwn, clearance_logic, seq_stat):\n",
    "    # CHECK: when adding the window filter (3, 28), and selecting seq_stat None, you get 323, matching Tal version\n",
    "    time_txnm = f'{timetx[0]}-{timetx[1]}' if timetx != (-np.inf, np.inf) else ('any')\n",
    "    outcome_t = f'Outcome_allmdro_{clrlgc}_tx{time_txnm}_abx{maxabx if maxabx != np.inf else \"any\"}_w{w[0]}-{w[1]}_{sqst}'\n",
    "    outcome_fun = partial(get_outcome, w, timetx, maxabx, clrlgc, sqst, MIN_READS)\n",
    "    outcome[outcome_t] = outcome.groupby('StudyID').apply(outcome_fun, include_groups=False).reset_index().drop(['StudyID', 'level_1'], axis=1)\n",
    "    if outcome[outcome_t].notna().sum() < MIN_SAMPLES or outcome[outcome_t].dropna().value_counts().min() < MIN_LEAST_REPR_LABEL:\n",
    "        print('SKIPPED: ', outcome_t, outcome[outcome_t].notna().sum(), 'samples')\n",
    "        outcome.drop(columns=[outcome_t], inplace=True)\n",
    "        continue\n",
    "    print('Samples: ', outcome[outcome_t].dropna().shape[0])\n",
    "    print('Patients: ', len(outcome[outcome[outcome_t].notna()].StudyID.value_counts()))\n",
    "    print(outcome[outcome_t].dropna().value_counts())\n",
    "outcome.to_csv('Outcome_allmdro.csv', index=None)\n",
    "    \n",
    "    \n",
    "## VRE SPECIFIC\n",
    "#windows = [(3, 28)]#, (3, 21), (7, 21), (7, 28), (3, 14)]\n",
    "#time_from_tx = [(-np.inf, np.inf), (0, 28)]\n",
    "#abxbtwn = [np.inf]\n",
    "#clearance_logic = ['allclr']\n",
    "#seq_stat = ['seq2023']#, 'seq2020', None]\n",
    "#mdro_span = ['VRE']\n",
    "#gv = partial(get_vars, mdro_span)\n",
    "#outcome_vre = islts.groupby('StudyID').apply(gv, include_groups=False).reset_index().drop('level_1', axis=1)\n",
    "#print('samples:', outcome_vre[outcome_vre.Positive].shape[0])\n",
    "#for w, timetx, maxabx, clrlgc, sqst in product(windows, time_from_tx, abxbtwn, clearance_logic, seq_stat):\n",
    "#    time_txnm = f'{timetx[0]}-{timetx[1]}' if timetx != (-np.inf, np.inf) else ('any')\n",
    "#    outcome_t = f'Outcome_vremdro_{clrlgc}_tx{time_txnm}_abx{maxabx if maxabx != np.inf else \"any\"}_w{w[0]}-{w[1]}_{sqst}'\n",
    "#    outcome_fun = partial(get_outcome, w, timetx, maxabx, clrlgc, sqst)\n",
    "#    outcome_vre[outcome_t] = outcome_vre.groupby('StudyID').apply(outcome_fun, include_groups=False).reset_index().drop(['StudyID', 'level_1'], axis=1)\n",
    "#    if outcome_vre[outcome_t].notna().sum() < MIN_SAMPLES:\n",
    "#        print('SKIPPED: ', outcome_t, outcome_vre[outcome_t].notna().sum(), 'samples')\n",
    "#        outcome_vre.drop(columns=[outcome_t], inplace=True)\n",
    "#        continue\n",
    "#    print(outcome_vre[outcome_t].dropna().shape)\n",
    "#    print(outcome_vre[outcome_t].dropna().value_counts())\n",
    "#outcome_vre.to_csv('Outcome_vremdro.csv', index=None)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     StudyID  StoolID SampleDate     TxDate    VRE  seq2020  seq2022  seq2023 ESBL KPC                                                                                                          PATH  Clear  Positive  StoolID_nxt SampleDate_nxt TxDate_nxt VRE_nxt seq2020_nxt seq2022_nxt seq2023_nxt ESBL_nxt KPC_nxt                                                                                                      PATH_nxt Clear_nxt Positive_nxt tx_to_sample_days sample_to_future_days  course_days_total  course_days_to_sample  course_days_to_future  course_days_since_last_exposure  course_days_between Outcome_vremdro_allclr_txany_abx10_w5-12_seq2023 Outcome_vremdro_allclr_tx0-10_abx10_w5-12_seq2023\n",
      "50        19    30661 2015-06-17 2015-06-13  35327    False     True     True   No  No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/30661.pe_ext.fasta.gz  False      True      30675.0     2015-06-25 2015-06-13   35343       False       False       False       No      No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/30675.pe_ext.fasta.gz     False         True                 4                   8.0                  8                    5.0                    8.0                              0.0                  4.0                                      Persistence                                       Persistence\n",
      "131       39    31068 2016-02-25 2016-02-18  35609    False     True     True  NaN  No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/31068.pe_ext.fasta.gz  False      True      31074.0     2016-03-02 2016-02-18   35612       False       False       False       No      No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/31074.pe_ext.fasta.gz     False         True                 7                   6.0                108                    8.0                   11.0                              0.0                  4.0                                      Persistence                                       Persistence\n",
      "262       61    30891 2015-10-19 2015-10-10  35512    False     True     True   No  No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/30891.pe_ext.fasta.gz  False      True      30910.0     2015-10-27 2015-10-10   35523       False       False       False       No      No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/30910.pe_ext.fasta.gz     False         True                 9                   8.0                 79                    7.0                    7.0                              5.0                  0.0                                      Persistence                                       Persistence\n",
      "588      110    30537 2015-04-13 2015-04-06  35728     True     True     True   No  No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/30537.pe_ext.fasta.gz  False      True      30553.0     2015-04-21 2015-04-06     Yes       False       False       False       No      No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/30553.pe_ext.fasta.gz     False         True                 7                   8.0                  6                    6.0                    6.0                              0.0                  1.0                                      Persistence                                       Persistence\n",
      "1120     186    31331 2016-10-03 2016-09-24  35748    False    False     True   No  No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/31331.pe_ext.fasta.gz  False      True      31347.0     2016-10-12 2016-09-24      No       False       False       False       No      No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/31347.pe_ext.fasta.gz      True        False                 9                   9.0                 22                    4.0                    4.0                              3.0                  0.0                                        Clearance                                         Clearance\n",
      "1303     229    31218 2016-06-23 2016-06-18  35679    False    False     True   No  No  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/31218.pe_ext.fasta.gz  False      True      31231.0     2016-07-01 2016-06-18      No       False       False       False       No   35692  /manitou/pmg/projects/korem_lab/Projects/ACU_PLT/mmmbp2/tmp_path2/EXT/extended_contigs/31231.pe_ext.fasta.gz      True        False                 5                   8.0                 10                    6.0                    8.0                              3.0                  2.0                                        Clearance                                         Clearance\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(outcome_vre[outcome_vre['Outcome_vremdro_allclr_tx0-10_abx10_w5-12_seq2023'].notna()].iloc[:10,:].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoolID</th>\n",
       "      <th>Sample_Date</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>VRE</th>\n",
       "      <th>ESBL</th>\n",
       "      <th>KPC</th>\n",
       "      <th>TxDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>31117</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>230.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2016-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>32073</td>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>396.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>32077</td>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>405.0</td>\n",
       "      <td>No</td>\n",
       "      <td>35985</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>32088</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>405.0</td>\n",
       "      <td>35987</td>\n",
       "      <td>35986</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>32089</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>421.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>32090</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>414.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>32096</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>405.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>32098</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>403.0</td>\n",
       "      <td>36009</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>32101</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>264.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>32106</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>398.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>32107</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>472.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>32108</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>396.0</td>\n",
       "      <td>35994</td>\n",
       "      <td>35993</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>32119</td>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>380.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>32138</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>483.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>32141</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>484.0</td>\n",
       "      <td>36022</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>32152</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>495.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>32173</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>498.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>32177</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>498.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>32184</td>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>488.0</td>\n",
       "      <td>No</td>\n",
       "      <td>36102</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>32196</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>508.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>32197</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>515.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>32198</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>512.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>32221</td>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>512.0</td>\n",
       "      <td>36135</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>32235</td>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>524.0</td>\n",
       "      <td>36150</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>32238</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>526.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StoolID Sample_Date  StudyID    VRE   ESBL KPC     TxDate\n",
       "1049   31117  2016-04-04    230.0     No     No  No 2016-03-31\n",
       "1954   32073  2019-11-14    396.0     No     No  No        NaT\n",
       "1958   32077  2019-11-21    405.0     No  35985  No        NaT\n",
       "1967   32088  2020-01-14    405.0  35987  35986  No        NaT\n",
       "1968   32089  2020-01-14    421.0     No     No  No        NaT\n",
       "1969   32090  2020-01-14    414.0     No     No  No        NaT\n",
       "1974   32096  2020-01-29    405.0     No     No  No        NaT\n",
       "1976   32098  2020-02-03    403.0  36009     No  No        NaT\n",
       "1979   32101  2020-02-10    264.0     No     No  No        NaT\n",
       "1983   32106  2020-02-21    398.0     No     No  No        NaT\n",
       "1984   32107  2020-02-24    472.0     No     No  No        NaT\n",
       "1985   32108  2020-02-24    396.0  35994  35993  No        NaT\n",
       "1994   32119  2020-11-17    380.0     No     No  No        NaT\n",
       "2009   32138  2021-05-17    483.0     No     No  No        NaT\n",
       "2012   32141  2021-06-08    484.0  36022     No  No        NaT\n",
       "2023   32152  2021-11-03    495.0     No     No  No        NaT\n",
       "2044   32173  2021-12-10    498.0     No     No  No        NaT\n",
       "2048   32177  2021-12-23    498.0     No     No  No        NaT\n",
       "2055   32184  2022-01-19    488.0     No  36102  No        NaT\n",
       "2068   32196  2022-04-05    508.0     No     No  No        NaT\n",
       "2069   32197  2022-04-05    515.0     No     No  No        NaT\n",
       "2070   32198  2022-04-07    512.0     No     No  No        NaT\n",
       "2093   32221  2022-06-03    512.0  36135     No  No        NaT\n",
       "2107   32235  2022-06-24    524.0  36150     No  No        NaT\n",
       "2110   32238  2022-07-05    526.0     No     No  No        NaT"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#missing_from_stlbk = [e for e in missing if not any(stlbk.StoolID.isin([e]))]\n",
    "#print(len(missing_from_stlbk))\n",
    "#missing_from_stlbk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoolID</th>\n",
       "      <th>SampleDate</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>TxDate</th>\n",
       "      <th>VRE</th>\n",
       "      <th>seq2023</th>\n",
       "      <th>seq2020</th>\n",
       "      <th>seq2022</th>\n",
       "      <th>seqALL</th>\n",
       "      <th>PostHGFRC2</th>\n",
       "      <th>ESBL</th>\n",
       "      <th>KPC</th>\n",
       "      <th>PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>30004</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35888</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>26265429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35022</td>\n",
       "      <td>/manitou/pmg/projects/korem_lab/Projects/ACU_P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StoolID SampleDate StudyID TxDate    VRE  seq2023  seq2020  seq2022  \\\n",
       "1771    30004 2014-04-07       5    NaT  35888     True    False    False   \n",
       "\n",
       "      seqALL  PostHGFRC2 ESBL    KPC  \\\n",
       "1771    True  26265429.0  NaN  35022   \n",
       "\n",
       "                                                   PATH  \n",
       "1771  /manitou/pmg/projects/korem_lab/Projects/ACU_P...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "islts.loc[islts.StoolID == 30004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2056, 7)\n",
      "(2036, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145721/418072466.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  islts['Positive'] = islts[['VRE', 'ESBL', 'KPC']].applymap(lambda v: v != 'No' and pd.notnull(v)).any(axis=1)\n"
     ]
    }
   ],
   "source": [
    "######### TAL VERSION ##########\n",
    "islts = pd.read_excel('PLT_all_stool_isolates.xlsx')\n",
    "\n",
    "islts.rename(columns = {'Stool ID':'StoolID', 'VRE +/-':'VRE'}, inplace = True)\n",
    "\n",
    "islts = islts[islts.StudyID.notnull()] #lose 2 samples\n",
    "islts = islts[~islts.ESBLisolate.apply(lambda v: type(v) is str and \"SAME AS\" in v)]#remove 4 duplciates\n",
    "islts.head()\n",
    "\n",
    "islts['ESBL'] = islts.ESBLisolate.replace([0, 'N', 'No', '-', 'n', 'N (NO MAC GROWTH)', 'N (ODD)'], 'No').\\\n",
    "    replace(['?', '35379- FALSE + DUE TO BAD PLATES', '35387 (FALSE + DUE TO BAD PLATES)',\n",
    "            '35393 (FALSE + DUE TO BAD PLATES)'], np.nan).\\\n",
    "     apply(lambda v: np.nan if type(v) is str and 'BOTH FALSE + DUE TO BAD PLATES' in v else v)\n",
    "\n",
    "islts['KPC'] = islts.KPCisolate.replace(['N', 'n', '-', 0, 'N (AFTER SUB CX)', 'N (NO MAC GROWTH)'], 'No').\\\n",
    "                 replace(['?', 'N (SMALL BLUE?)', '?N '], np.nan)\n",
    "\n",
    "islts['VRE'] = islts.VRE.replace(['N', '-', 'n', '0'], 'No').replace(['+ (NEG on reculture 3/31)', 'NEG on reculture 4/12'], np.nan).\\\n",
    "    replace(['+', '+ (not pink)', '+ (mauve + blue)', '+ (pink + white)', '+ (mauve)', '+ (white)'], 'Yes')\n",
    "\n",
    "\n",
    "islts = islts.drop(['ESBLisolate', 'KPCisolate'], axis = 1)\n",
    "\n",
    "#PTNT 186 IS WEIRD W 31331 31332\n",
    "dupstlid = [31012, 30522, 30100, 30176, 30947, 30327, 30483, 30496, 30919, 31098, \n",
    "            31332, 30973, 31277, 31820, 31501, 31899, 31828, 31884, 31808, 32033]\n",
    "\n",
    "print(islts.shape)\n",
    "islts = islts[~islts.StoolID.isin(dupstlid)]\n",
    "print(islts.shape)\n",
    "islts['Clear'] = (islts[['VRE', 'ESBL', 'KPC']] == 'No').all(1)\n",
    "islts['Positive'] = islts[['VRE', 'ESBL', 'KPC']].applymap(lambda v: v != 'No' and pd.notnull(v)).any(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcomeTK(g):\n",
    "    g = g.sort_values('SampleDate')\n",
    "    g = g[(g[['Clear', 'Positive']] == True).any(axis=1)]\n",
    "    gj = g.join(g.shift(-1), rsuffix='_nxt')\n",
    "    gj = gj[((gj.SampleDate_nxt - gj.SampleDate) >= min_t) & ((gj.SampleDate_nxt - gj.SampleDate) < max_t)]\n",
    "    gj['Outcome'] = gj.apply(lambda r: 'Clearance' if r['Clear_nxt'] == True else 'Persistence' if r['Positive_nxt'] == True else np.nan, axis = 1)\n",
    "    return gj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyID</th>\n",
       "      <th>StoolID</th>\n",
       "      <th>SampleDate</th>\n",
       "      <th>TxDate</th>\n",
       "      <th>VRE</th>\n",
       "      <th>ESBL</th>\n",
       "      <th>KPC</th>\n",
       "      <th>Clear</th>\n",
       "      <th>Positive</th>\n",
       "      <th>StoolID_nxt</th>\n",
       "      <th>SampleDate_nxt</th>\n",
       "      <th>TxDate_nxt</th>\n",
       "      <th>VRE_nxt</th>\n",
       "      <th>ESBL_nxt</th>\n",
       "      <th>KPC_nxt</th>\n",
       "      <th>Clear_nxt</th>\n",
       "      <th>Positive_nxt</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>30004</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35022</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30011.0</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>30017</td>\n",
       "      <td>2014-04-28</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>35893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35024, 35025</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30019.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>35894</td>\n",
       "      <td>35027</td>\n",
       "      <td>35026</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>30019</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>35894</td>\n",
       "      <td>35027</td>\n",
       "      <td>35026</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30029.0</td>\n",
       "      <td>2014-05-20</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>35834</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>30029</td>\n",
       "      <td>2014-05-20</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>35834</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30036.0</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>35835</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>30006</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>35889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30010.0</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>35805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>423</td>\n",
       "      <td>31920</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35954</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>31927.0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>No</td>\n",
       "      <td>P:35958 B:35959</td>\n",
       "      <td>35957</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>423</td>\n",
       "      <td>31927</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>No</td>\n",
       "      <td>P:35958 B:35959</td>\n",
       "      <td>35957</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>31937.0</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Clearance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>424</td>\n",
       "      <td>31982</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35965</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>31986.0</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35966</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>439</td>\n",
       "      <td>32019</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35974</td>\n",
       "      <td>35971</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32024.0</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35976</td>\n",
       "      <td>35978</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>439</td>\n",
       "      <td>32024</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35976</td>\n",
       "      <td>35978</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32028.0</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35979</td>\n",
       "      <td>35977</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Persistence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    StudyID  StoolID SampleDate     TxDate    VRE             ESBL  \\\n",
       "0         5    30004 2014-04-07        NaT  35888              NaN   \n",
       "1         6    30017 2014-04-28 2014-03-26  35893              NaN   \n",
       "2         6    30019 2014-05-05 2014-03-26  35894            35027   \n",
       "3         6    30029 2014-05-20 2014-03-26  35834               No   \n",
       "6         9    30006 2014-04-11 2014-04-07  35889              NaN   \n",
       "..      ...      ...        ...        ...    ...              ...   \n",
       "786     423    31920 2018-12-20        NaT  35954               No   \n",
       "787     423    31927 2019-01-03        NaT     No  P:35958 B:35959   \n",
       "788     424    31982 2019-03-29        NaT  35965               No   \n",
       "800     439    32019 2019-06-24        NaT  35974            35971   \n",
       "801     439    32024 2019-07-03        NaT  35976            35978   \n",
       "\n",
       "              KPC  Clear  Positive  StoolID_nxt SampleDate_nxt TxDate_nxt  \\\n",
       "0           35022  False      True      30011.0     2014-04-17        NaT   \n",
       "1    35024, 35025  False      True      30019.0     2014-05-05 2014-03-26   \n",
       "2           35026  False      True      30029.0     2014-05-20 2014-03-26   \n",
       "3              No  False      True      30036.0     2014-06-04 2014-03-26   \n",
       "6              No  False      True      30010.0     2014-04-16 2014-04-07   \n",
       "..            ...    ...       ...          ...            ...        ...   \n",
       "786            No  False      True      31927.0     2019-01-03        NaT   \n",
       "787         35957  False      True      31937.0     2019-01-17        NaT   \n",
       "788            No  False      True      31986.0     2019-04-10        NaT   \n",
       "800            No  False      True      32024.0     2019-07-03        NaT   \n",
       "801            No  False      True      32028.0     2019-07-10        NaT   \n",
       "\n",
       "    VRE_nxt         ESBL_nxt KPC_nxt Clear_nxt Positive_nxt      Outcome  \n",
       "0     35892              NaN      No     False         True  Persistence  \n",
       "1     35894            35027   35026     False         True  Persistence  \n",
       "2     35834               No      No     False         True  Persistence  \n",
       "3     35835               No      No     False         True  Persistence  \n",
       "6     35805              NaN      No     False         True  Persistence  \n",
       "..      ...              ...     ...       ...          ...          ...  \n",
       "786      No  P:35958 B:35959   35957     False         True  Persistence  \n",
       "787      No               No      No      True        False    Clearance  \n",
       "788   35966               No      No     False         True  Persistence  \n",
       "800   35976            35978      No     False         True  Persistence  \n",
       "801   35979            35977      No     False         True  Persistence  \n",
       "\n",
       "[323 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = islts.groupby('StudyID').apply(get_outcomeTK, include_groups=False).reset_index().drop('level_1', axis = 1)\n",
    "outcome = outcome[outcome.Positive]\n",
    "outcome\n",
    "\n",
    "# NOTE, to get 323 rows, the same as with grid version, set <= max_t in get_outcomeTK() not < max_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldX = pd.read_csv('mdro_pos.csv')\n",
    "x_samples=[int(e) for e in \"\"\"30661\n",
    "30038\n",
    "31068\n",
    "30049\n",
    "30371\n",
    "30891\n",
    "30104\n",
    "30434\n",
    "30537\n",
    "30542\n",
    "30266\n",
    "31022\n",
    "30512\n",
    "30927\n",
    "31140\n",
    "31581\n",
    "30939\n",
    "30788\n",
    "31141\n",
    "31224\n",
    "31307\n",
    "31110\n",
    "31194\n",
    "31268\n",
    "31777\n",
    "30572\n",
    "30096\n",
    "30165\n",
    "30094\n",
    "30230\n",
    "30355\n",
    "30316\n",
    "30688\n",
    "30394\n",
    "30543\n",
    "30665\n",
    "30582\n",
    "30853\n",
    "30758\n",
    "30848\n",
    "30725\n",
    "30875\n",
    "31227\n",
    "31424\n",
    "31708\n",
    "31456\n",
    "32015\"\"\".splitlines()]\n",
    "oldX = oldX.loc[oldX['Stool ID'].isin(x_samples), :]\n",
    "islts[islts.StoolID.isin(oldX['Stool ID'])].PATH.to_csv('oldX.list', header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "COPAN_INI_TMPLT = \"\"\"# enter all config in 'key = value' format\n",
    "app_name = cpg\n",
    "log_file_dir = logs # path relative to the executable\n",
    "log_level = 0 # possible values are 1ebug=0(includes Info and Error), Info=1(includes Error), Error=2, None=3\n",
    "log_to = 0 # possible values are Console=0, File=1, ConsoleAndFile=2\n",
    "sample_list = /burg/pmg/users/ic2465/Projects/MANU_copangraph/data/CAMISIMCoassembly/XNAME.txt\n",
    "graph_name = XNAME # name of graph prefix\n",
    "out_dir = /burg/pmg/users/ic2465/Projects/MANU_copangraph/data/CAMISIMCoassembly/\n",
    "divergence_threshold = XSD\n",
    "num_threads = 32\n",
    "max_separation = 75\n",
    "window_size = 10\n",
    "kmer_size = 15\n",
    "min_homology_overlap = 1000\n",
    "min_contiguity_overlap = 60\n",
    "max_jump = 200 # largest allowed gap within an alignment\n",
    "high_freq_kmer_filter = 1e-5 # remove the top 1-x percentile kmers where x is input\n",
    "fasta_file_ext = .fasta \n",
    "gfa_file_ext = .gfa\n",
    "node_color_file_ext = .ncolor.csv\n",
    "edge_color_file_ext = .ecolor.csv\n",
    "extended_contigs = true\n",
    "sensitive_mode = true\"\"\"\n",
    "\n",
    "copan_05 = COPAN_INI_TMPLT.replace('XNAME', 'oldX').replace('XSD', '0.05')\n",
    "copan_02 = COPAN_INI_TMPLT.replace('XNAME', 'oldX').replace('XSD', '0.02')\n",
    "with open('oldX_05.ini', 'w') as f:\n",
    "    f.write(copan_05)\n",
    "with open('oldX_02.ini', 'w') as f:\n",
    "    f.write(copan_02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
